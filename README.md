# Wrangle-OpenStreetMap-Data

### Project Overview
I was free to choose any area of the world in https://www.openstreetmap.org and use data munging techniques, such as assessing the quality of the data for validity, accuracy, completeness, consistency and uniformity, to clean the OpenStreetMap data for a part of the world that I cared about, I chose a city which had medium size as far as number of data points were concerned. The name of the city is Southampton, England. Finally, I was allowed to choose either MongoDB or SQL as the data schema to complete the project.

### What will I learn?
After completing the project, I was able to:

- Assess the quality of the data for validity, accuracy, completeness, consistency and uniformity.
- Parse and gather data from popular file formats such as .csv, .json, .xml, and .html
- Process data from multiple files or very large files that can be cleaned programmatically.
- Learn how to store, query, and aggregate data using MongoDB or SQL.

### Why this Project?
What’s so hard about retrieving data from databases or various files formats? You grab some data from this file and that database, clean it up, merge it, and then feed it into your state of the art, deep learning algorithm … Right?

But the reality is this -- anyone who has worked with data extensively knows it is an absolute nightmare to get data from different data sources to play well with each other.

And this project was able to teach me all of the skills I need to deal with even the most nightmarish data wrangling scenarios.

### Why is this Important to my Career?
The skills in this project are some of the most important for my career. Any data analyst will need to wrangle data before they can do any analysis. At Udacity, how would they know when students submit projects unless they made sure to report the timestamp? How would they be able to compare that to when students finish watching videos unless they built data pipelines to get all of this information in one place? Data analysts help with collecting and cleaning the data, or what is often called "data wrangling."

Data analysts and data scientists can spend 50%-80% of their time data wrangling. A huge benefit of this is that collecting and cleaning data means one will know the data very well, and be better prepared to analyze it.
